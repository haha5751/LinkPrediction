{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a87427db-0275-4f16-b0d8-ab31178ac6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pylab as plt\n",
    "import random as rnd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2dff404-7eac-4e2c-9ea6-b8808b4f0d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.read_edgelist(\"ChCh-Miner_durgbank-chem-chem.tsv\") # Our dataset is stored as an edge list, we use networkx to read the file into a Graph object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30e6f7a9-8c78-47df-833f-89f27890f5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictor_Baseline(): # Our baseline predictor, taken from the PS5 solutions\n",
    "    return rnd.random()\n",
    "\n",
    "def predictor_Jaccard(Gx,i,j): # Our Jaccard predictor, taken from the PS5 solutions\n",
    "    j_temp = nx.jaccard_coefficient(Gx, [(i,j)])\n",
    "    for u,v,p in j_temp:\n",
    "        jaccard = p\n",
    "    n = Gx.order()\n",
    "    return jaccard + rnd.uniform(0,1/(10*n))\n",
    "\n",
    "def predictor_DegreeProd(Gx,i,j): # Our Jaccard predictor, taken from the PS5 solutions\n",
    "    d_temp = nx.preferential_attachment(Gx, [(i,j)])\n",
    "    for u,v,p in d_temp:\n",
    "        degreeprod = p\n",
    "    n = Gx.order()\n",
    "    return degreeprod + rnd.uniform(0,1/(10*n))\n",
    "\n",
    "def predictor_iforget(Gx,i,j): # Our <insert> predictor, created by us\n",
    "    pass\n",
    "\n",
    "def predictor_randomwalk(Gx,i,j): # Our <insert> predictor, created by us\n",
    "    pass\n",
    "\n",
    "def get_candidateEdges(G): # This function returns all the non edges in graph G\n",
    "    nonEdges = list(nx.non_edges(G))\n",
    "    return nonEdges\n",
    "\n",
    "def apply_Predictors(G, Y): # This functions stores the results from all of our predictors in an np array \n",
    "    Y2 = get_candidateEdges(G) # First, we get the edges that we want our predictors to make a prediction on\n",
    "    table = np.ndarray((len(Y2), 8), dtype = object) # Here, we are creating the np array to store all of our results beforehand, this is done to speed up program runtime\n",
    "    table[:,0] = int(len(Y2)) # We make sure to cast the int type to the first two columns\n",
    "    table[:,1] = int(len(Y2)) # These first two columns will store the nodes within the edge, we need them in int form in order to check if they are in the missing edge list\n",
    "    table[:,2] = int(len(Y2)) # We cast the third column to int because this will store the tau values, 0 = False and 1 = True\n",
    "    table[:,3:] = float(len(Y2)) # The rest of the columns are casted to float format because they will contain the results of our predictors\n",
    "    counter = 0 # This counter will be used to add an entry to the closest vacant spot in our np array\n",
    "\n",
    "    for link in Y2: # We iterate through the candidate edges, having our predictors make an estimation on the liklihood of an edge being a real missing edge \n",
    "        if(link[0], link[1]) in Y: # We check if the candidate edge is a true missing edge \n",
    "            tau = 1\n",
    "        else:\n",
    "            tau = 0 # If the candidate edge is not within the missing edge list, then tau = 0\n",
    "        baseline = float(predictor_Baseline()) # We make sure to cast the results of our predictors to floats\n",
    "        jaccard = float(predictor_Jaccard(G, link[0], link[1])) # We do this because the output of the predictors are initially strings, which do not work within a homogenous np array\n",
    "        degreeProd = float(predictor_DegreeProd(G, link[0], link[1]))\n",
    "        NewPredictor1 = 0 # Kurt, here is where you will make the function call to the new predictors, make sure the return of the function is a float \n",
    "        NewPredictor2 = 0\n",
    "        \n",
    "        table[counter,:] = [link[0], link[1], tau, baseline, jaccard, degreeProd, NewPredictor1, NewPredictor2] # Here we are adding an entry to the np array in the closest vacant spot\n",
    "        counter += 1 # Increment counter to the index of the closest vacant spot\n",
    "\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c35c3953-b768-40bc-8481-a9efdf4b5c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateGo(G, alpha): # This function creates the observed graph from the original graph\n",
    "    Go = G.copy() # We first make a copy of the original graph\n",
    "    mapping = {old_label:new_label for new_label, old_label in enumerate(Go.nodes())} # The nodes in this graph are in this form: XX00000, this code is modified from stackoverflow\n",
    "    Go = nx.relabel_nodes(Go, mapping) # We relabel the node names into integers because np arrays are homogenous data structures and cannot contain strings and numbers \n",
    "    missingEdges = [] # This list will contain all the missing edges which remove from Go\n",
    "    randomNum = 0\n",
    "    \n",
    "    for edge in Go.edges(): # We iterate through the edges of Go\n",
    "        randomNum = np.random.uniform(0, 1) # We generate a random number between 0 and 1\n",
    "        if randomNum > alpha: # We use alpha where 0 < alpha < 1 to determine how many edges will be removed from the Go\n",
    "            Go.remove_edge(edge[0], edge[1]) \n",
    "            missingEdges.append(edge) # We make sure to store the edge which was removed \n",
    "    \n",
    "    return Go, missingEdges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efc59238-0b2c-4b52-84ee-31309132c350",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tabulate_TPR_FPR(S): # This code was used from our PS5\n",
    "    tkTrue = 0\n",
    "    tkFalse = 0\n",
    "    TPR = []\n",
    "    FPR = []\n",
    "    T = 0\n",
    "    F = 0\n",
    "    \n",
    "    for i in range(0, len(S)): # Iterate once through S in order to determine the normalizing constants\n",
    "        if S[i][2] == 1:\n",
    "            T += 1\n",
    "        else:\n",
    "            F += 1\n",
    "            \n",
    "    for j in range(0, len(S)): # Iterate again to calculate the TPR and FPR\n",
    "        if(S[j][2]) == 1:\n",
    "            tkTrue += 1\n",
    "        else:\n",
    "            tkFalse += 1\n",
    "        TPR.append(tkTrue / T)\n",
    "        FPR.append(tkFalse / F)\n",
    "        \n",
    "    columnOne = S[:, 0] # Here we are getting the columns of the table in the desired return format\n",
    "    columnTwo = S[:, 1]\n",
    "    columnThree = S[:, 2]\n",
    "    columnFour = np.array(TPR)\n",
    "    columnFive = np.array(FPR)\n",
    "    columnSix = S[:, 3]\n",
    "\n",
    "    columnOne = columnOne.reshape(len(columnOne), 1) # Reshaping columns, turning them into columns instead of horizontal lists\n",
    "    columnTwo = columnTwo.reshape(len(columnTwo), 1)\n",
    "    columnThree = columnThree.reshape(len(columnThree), 1)\n",
    "    columnFour = columnFour.reshape(len(columnFour), 1)\n",
    "    columnFive = columnFive.reshape(len(columnFive), 1)\n",
    "    columnSix = columnSix.reshape(len(columnSix), 1)\n",
    "\n",
    "    table = np.hstack((columnOne, columnTwo)) # Here we are combining those columns into the table in the desired return format\n",
    "    table = np.hstack((table, columnThree))\n",
    "    table = np.hstack((table, columnFour))\n",
    "    table = np.hstack((table, columnFive))\n",
    "    table = np.hstack((table, columnSix))\n",
    "    return table    \n",
    "\n",
    "def calculate_AUC(TPR,FPR):\n",
    "    AUC = 0\n",
    "    TPR = np.insert(TPR, 0, 0) # Prepend 0\n",
    "    FPR = np.insert(FPR, 0, 0)\n",
    "    for i in range(1, len(TPR)):\n",
    "        AUC += TPR[i] * (FPR[i] - FPR[i - 1]) # calculate AUC according to lecture notes 4\n",
    "    return AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93d5a469-082c-4cdf-a0a5-5dcbc09dd13f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2780/3044039110.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnreps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mGo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmissing\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerateGo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mtable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mapply_Predictors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mcolumnOne\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtable\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# Here I am getting the columns of the table in the desired input format, this code was taken from our PS5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2780/4257400066.py\u001b[0m in \u001b[0;36mapply_Predictors\u001b[1;34m(G, Y)\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m             \u001b[0mtau\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;31m# If the candidate edge is not within the missing edge list, then tau = 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m         \u001b[0mbaseline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictor_Baseline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# We make sure to cast the results of our predictors to floats\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m         \u001b[0mjaccard\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictor_Jaccard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlink\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlink\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# We do this because the output of the predictors are initially strings, which do not work within a homogenous np array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[0mdegreeProd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictor_DegreeProd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlink\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlink\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import random as rnd\n",
    "seed = 703\n",
    "rnd.seed(seed)\n",
    "\n",
    "nreps = 3     \n",
    "alphas  = [.05, .15, .25, .35, .45, .55, .65, .75, .85, .95]  \n",
    "\n",
    "jaccardAUC = 0\n",
    "baselineAUC = 0\n",
    "degreeProdAUC = 0\n",
    "# predOneAUC = 0\n",
    "# predTwoAUC = 0\n",
    "\n",
    "AUCs_base = [] # for storing list of nreps AUCs from baseline\n",
    "AUCs_jacc = [] # for storing list of nreps AUCs from jaccard\n",
    "AUCs_degp = [] # for storing list of nreps AUCs from degree product\n",
    "# AUCs_predOne = []\n",
    "# AUCs_predTwo = []\n",
    "\n",
    "for alpha in alphas:\n",
    "    for r in range(nreps):\n",
    "        Go, missing = generateGo(G, alpha) \n",
    "        table = apply_Predictors(Go, missing) \n",
    "\n",
    "        columnOne = table[:, 0] # Here I am getting the columns of the table in the desired input format, this code was taken from our PS5 \n",
    "        columnTwo = table[:, 1] # We use the columns to create tables in the format needed for the tabulate_TPR_FPR and calculate_AUC function\n",
    "        columnThree = table[:, 2] # The first three columns are node i, node j, tau, in that order\n",
    "        columnFour = table[:, 3] # This column contains the baseline predictions\n",
    "        columnFive = table[:, 4] # This column contains the jaccard predictions\n",
    "        columnSix = table[:, 5] # This column contains the degree product predictions\n",
    "        # columnSeven = table[:, 6] # This column contains the <insert> predictions\n",
    "        # columnEight = table[:, 7] # This column contains the <insert> predictions\n",
    "\n",
    "        columnOne = columnOne.reshape(len(columnOne), 1) # Reshaping columns, turning them into columns instead of horizontal lists\n",
    "        columnTwo = columnTwo.reshape(len(columnTwo), 1)\n",
    "        columnThree = columnThree.reshape(len(columnThree), 1)\n",
    "        columnFour = columnFour.reshape(len(columnFour), 1)\n",
    "        columnFive = columnFive.reshape(len(columnFive), 1)\n",
    "        columnSix = columnSix.reshape(len(columnSix), 1)\n",
    "        # columnSeven = columnThree.reshape(len(columnSeven), 1)\n",
    "        # columnEight = columnFour.reshape(len(columnEight), 1)\n",
    "\n",
    "        baselineTable = np.hstack((columnOne, columnTwo)) # Here we are combining the columns of the table in the desired return format\n",
    "        baselineTable = np.hstack((baselineTable, columnThree))\n",
    "        baselineTable = np.hstack((baselineTable, columnFour))\n",
    "        baselineTable = baselineTable[np.argsort(baselineTable[:, 3])[::-1]] # Here we are sorting the table by the score column in descending order\n",
    "\n",
    "        jaccardTable = np.hstack((columnOne, columnTwo)) \n",
    "        jaccardTable = np.hstack((jaccardTable, columnThree)) \n",
    "        jaccardTable = np.hstack((jaccardTable, columnFive))\n",
    "        jaccardTable = jaccardTable[np.argsort(jaccardTable[:, 3])[::-1]]\n",
    "\n",
    "        degreeProductTable = np.hstack((columnOne, columnTwo)) \n",
    "        degreeProductTable = np.hstack((degreeProductTable, columnThree))\n",
    "        degreeProductTable = np.hstack((degreeProductTable, columnSix))\n",
    "        degreeProductTable = degreeProductTable[np.argsort(degreeProductTable[:, 3])[::-1]]\n",
    "\n",
    "        # newPredictorOneTable = np.hstack((columnOne, columnTwo)) \n",
    "        # newPredictorOneTable = np.hstack((newPredictorOneTable, columnThree))\n",
    "        # newPredictorOneTable = np.hstack((newPredictorOneTable, columnSix))\n",
    "        # newPredictorOneTable = newPredictorOneTable[np.argsort(newPredictorOneTable[:, 3])[::-1]]\n",
    "\n",
    "        # newPredictorTwoTable = np.hstack((columnOne, columnTwo)) \n",
    "        # newPredictorTwoTable = np.hstack((newPredictorTwoTable, columnThree))\n",
    "        # newPredictorTwoTable = np.hstack((newPredictorTwoTable, columnSix))\n",
    "        # newPredictorTwoTable = newPredictorTwoTable[np.argsort(newPredictorTwoTable[:, 3])[::-1]]\n",
    "\n",
    "        baselineTable = tabulate_TPR_FPR(baselineTable) # Here we are tabulating the tables and getting the TPR and FPR \n",
    "        jaccardTable = tabulate_TPR_FPR(jaccardTable)\n",
    "        degreeProductTable = tabulate_TPR_FPR(degreeProductTable)\n",
    "        # newPredictorOneTable = tabulate_TPR_FPR(newPredictorOneTable)\n",
    "        # newPredictorTwoTable = tabulate_TPR_FPR(newPredictorTwoTable)\n",
    "\n",
    "        baselineAUC += calculate_AUC(baselineTable[:, 3], baselineTable[:, 4]) # Once we have tabulated the tables, we get the AUC for each predictor\n",
    "        jaccardAUC += calculate_AUC(jaccardTable[:, 3], jaccardTable[:, 4])\n",
    "        degreeProdAUC += calculate_AUC(degreeProductTable[:, 3], degreeProductTable[:, 4])\n",
    "        # predOneAUC += calculate_AUC(newPredictorOneTable[:, 3], newPredictorOneTable[:, 4])\n",
    "        # predTwoAUC += calculate_AUC(newPredictorTwoTable[:, 3], newPredictorTwoTable[:, 4])\n",
    "        \n",
    "    baselineAUC /= nreps\n",
    "    jaccardAUC /= nreps\n",
    "    degreeProdAUC /= nreps\n",
    "    # predOneAUC /= nreps\n",
    "    # predTwoAUC /= nreps\n",
    "    \n",
    "    AUCs_base.append(baselineAUC)\n",
    "    AUCs_degp.append(degreeProdAUC)\n",
    "    AUCs_jacc.append(jaccardAUC)\n",
    "    # AUCs_predOne.append(predOneAUC)\n",
    "    # AUCs_predTwo.append(predTwoAUC)\n",
    "    \n",
    "    baselineAUC = 0\n",
    "    jaccardAUC = 0\n",
    "    degreeProdAUC = 0\n",
    "    # predOneAUC = 0\n",
    "    # predTwoAUC = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490c766d-fcaa-4503-becf-29fac53905b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (16, 8)) # This code is taken from the PS5 solutions and our own PS5\n",
    "ax1 = fig.add_subplot(111)\n",
    "plt.title(\"AUCs For All Predictors at Various \\u03B1 Values\")\n",
    "plt.plot(alphas, AUCs_base, 'bo-', alpha = 0.5, label = 'Baseline')\n",
    "plt.plot(alphas, AUCs_jacc, 'rs-', alpha = 0.5, label = 'Jaccard')\n",
    "plt.plot(alphas, AUCs_degp, 'gv-', alpha = 0.5, label = 'Degree Product')\n",
    "# plt.plot(alphas, AUCs_predOne, 'o1-', alpha = 0.5, label = 'New Predictor One')\n",
    "# plt.plot(alphas, AUCs_predTwo, 'pD-', alpha = 0.5, label = 'New Predictor Two')\n",
    "plt.legend(loc = \"lower right\")\n",
    "plt.xlabel(\"\\u03B1 Values\")\n",
    "plt.ylabel(\"AUCs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cef9c6e-623b-4ed4-9b86-e65f381454e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Go, missing = generateGo(G, .87) \n",
    "table = apply_Predictors(Go, missing) \n",
    "columnOne = table[:, 0] # Here I am getting the columns of the table in the desired input format, this code was taken from our PS5 \n",
    "columnTwo = table[:, 1] # We use the columns to create tables in the format needed for the tabulate_TPR_FPR and calculate_AUC function\n",
    "columnThree = table[:, 2] # The first three columns are node i, node j, tau, in that order\n",
    "columnFour = table[:, 3] # This column contains the baseline predictions\n",
    "columnFive = table[:, 4] # This column contains the jaccard predictions\n",
    "columnSix = table[:, 5] # This column contains the degree product predictions\n",
    "# columnSeven = table[:, 6] # This column contains the <insert> predictions\n",
    "# columnEight = table[:, 7] # This column contains the <insert> predictions\n",
    "\n",
    "columnOne = columnOne.reshape(len(columnOne), 1) # Reshaping columns, turning them into columns instead of horizontal lists\n",
    "columnTwo = columnTwo.reshape(len(columnTwo), 1)\n",
    "columnThree = columnThree.reshape(len(columnThree), 1)\n",
    "columnFour = columnFour.reshape(len(columnFour), 1)\n",
    "columnFive = columnFive.reshape(len(columnFive), 1)\n",
    "columnSix = columnSix.reshape(len(columnSix), 1)\n",
    "# columnSeven = columnThree.reshape(len(columnSeven), 1)\n",
    "# columnEight = columnFour.reshape(len(columnEight), 1)\n",
    "\n",
    "baselineTable = np.hstack((columnOne, columnTwo)) # Here we are combining the columns of the table in the desired return format\n",
    "baselineTable = np.hstack((baselineTable, columnThree))\n",
    "baselineTable = np.hstack((baselineTable, columnFour))\n",
    "baselineTable = baselineTable[np.argsort(baselineTable[:, 3])[::-1]] # Here we are sorting the table by the score column in descending order\n",
    "\n",
    "jaccardTable = np.hstack((columnOne, columnTwo)) \n",
    "jaccardTable = np.hstack((jaccardTable, columnThree)) \n",
    "jaccardTable = np.hstack((jaccardTable, columnFive))\n",
    "jaccardTable = jaccardTable[np.argsort(jaccardTable[:, 3])[::-1]]\n",
    "\n",
    "degreeProductTable = np.hstack((columnOne, columnTwo)) \n",
    "degreeProductTable = np.hstack((degreeProductTable, columnThree))\n",
    "degreeProductTable = np.hstack((degreeProductTable, columnSix))\n",
    "degreeProductTable = degreeProductTable[np.argsort(degreeProductTable[:, 3])[::-1]]\n",
    "\n",
    "# newPredictorOneTable = np.hstack((columnOne, columnTwo)) \n",
    "# newPredictorOneTable = np.hstack((newPredictorOneTable, columnThree))\n",
    "# newPredictorOneTable = np.hstack((newPredictorOneTable, columnSix))\n",
    "# newPredictorOneTable = newPredictorOneTable[np.argsort(newPredictorOneTable[:, 3])[::-1]]\n",
    "\n",
    "# newPredictorTwoTable = np.hstack((columnOne, columnTwo)) \n",
    "# newPredictorTwoTable = np.hstack((newPredictorTwoTable, columnThree))\n",
    "# newPredictorTwoTable = np.hstack((newPredictorTwoTable, columnSix))\n",
    "# newPredictorTwoTable = newPredictorTwoTable[np.argsort(newPredictorTwoTable[:, 3])[::-1]]\n",
    "\n",
    "baselineTable = tabulate_TPR_FPR(baselineTable) # Here we are tabulating the tables and getting the TPR and FPR \n",
    "jaccardTable = tabulate_TPR_FPR(jaccardTable)\n",
    "degreeProductTable = tabulate_TPR_FPR(degreeProductTable)\n",
    "# newPredictorOneTable = tabulate_TPR_FPR(newPredictorOneTable)\n",
    "# newPredictorTwoTable = tabulate_TPR_FPR(newPredictorTwoTable)\n",
    "\n",
    "baselineAUC = calculate_AUC(baselineTable[:, 3], baselineTable[:, 4]) # Once we have tabulated the tables, we get the AUC for each predictor\n",
    "jaccardAUC = calculate_AUC(jaccardTable[:, 3], jaccardTable[:, 4])\n",
    "degreeProductAUC = calculate_AUC(degreeProductTable[:, 3], degreeProductTable[:, 4])\n",
    "# predictorOneAUC = calculate_AUC(newPredictorOneTable[:, 3], newPredictorOneTable[:, 4])\n",
    "# predictorTwoAUC = calculate_AUC(newPredictorTwoTable[:, 3], newPredictorTwoTable[:, 4])\n",
    "\n",
    "text = \"Baseline AUC: {:.3f} \\n\\nJaccard AUC: {:.3f} \\n\\nDegree Product AUC: {:.3f} \\n\\nNP1 AUC: {:.3f} \\n\\nNP2 AUC: {:.3f}\".format(baselineAUC, jaccardAUC, degreeProductAUC, 0, 0)\n",
    "fig = plt.figure(figsize = (16, 8)) # This code is taken from the PS5 solutions and our own PS5\n",
    "ax1 = fig.add_subplot(111)\n",
    "plt.title(\"FPR vs. TPR For All Predictors, \\u03B1 = 0.87\")\n",
    "plt.plot(baselineTable[:,4], baselineTable[:,3], 'bo', alpha = 0.5, label = 'Baseline')\n",
    "plt.plot(jaccardTable[:,4], jaccardTable[:,3], 'rs', alpha = 0.5, label = 'Jaccard')\n",
    "plt.plot(degreeProductTable[:,4], degreeProductTable[:,3], 'gv', alpha = 0.5, label = 'Degree Product')\n",
    "# plt.plot(newPredictorOneTable[:,4], newPredictorOneTable[:,3], 'o1', alpha = 0.5, label = 'New Predictor One')\n",
    "# plt.plot(newPredictorTwoTable[:,4], newPredictorTwoTable[:,3], 'pD', alpha = 0.5, label = 'New Predictor Two')\n",
    "plt.annotate(text, xy = (0.75, 0.35), xycoords = \"axes fraction\", bbox = dict(facecolor = 'none', edgecolor = 'black', boxstyle = 'round, pad = 1'))\n",
    "plt.legend(loc = \"lower right\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d5be81-f199-4501-ac09-1e509881f671",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
