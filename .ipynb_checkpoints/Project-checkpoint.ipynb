{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "a87427db-0275-4f16-b0d8-ab31178ac6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pylab as plt\n",
    "import random as rnd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "30e6f7a9-8c78-47df-833f-89f27890f5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictor_Baseline():\n",
    "    return rnd.random()\n",
    "\n",
    "def predictor_Jaccard(Gx,i,j):\n",
    "    j_temp = nx.jaccard_coefficient(Gx, [(i,j)])\n",
    "    for u,v,p in j_temp:\n",
    "        jaccard = p\n",
    "    n = Gx.order()\n",
    "    return jaccard + rnd.uniform(0,1/(10*n))\n",
    "\n",
    "def predictor_DegreeProd(Gx,i,j):\n",
    "    d_temp = nx.preferential_attachment(Gx, [(i,j)])\n",
    "    for u,v,p in d_temp:\n",
    "        degreeprod = p\n",
    "    n = Gx.order()\n",
    "    return degreeprod + rnd.uniform(0,1/(10*n))\n",
    "\n",
    "def predictor_iforget(Gx,i,j):\n",
    "    pass\n",
    "\n",
    "def predictor_randomwalk(Gx,i,j):\n",
    "    pass\n",
    "\n",
    "def get_candidateEdges(G): # this function returns all the non edges in graph G\n",
    "    nonEdges = list(nx.non_edges(G))\n",
    "    return nonEdges\n",
    "\n",
    "def apply_Predictors(G, Y):\n",
    "    Y2 = get_candidateEdges(G) \n",
    "    table = np.ndarray((len(Y2), 8), dtype = object)\n",
    "    table[:,0] = int(len(Y2))\n",
    "    table[:,1] = int(len(Y2))\n",
    "    table[:,2] = int(len(Y2))\n",
    "    table[:,3:] = float(len(Y2))\n",
    "    counter = 0\n",
    "    \n",
    "    if(Y2[0][0], Y2[0][1]) in Y: # we start by creating the first entry in the table\n",
    "        tau = 1\n",
    "    else:\n",
    "        tau = 0\n",
    "    baseline = float(predictor_Baseline())\n",
    "    jaccard = float(predictor_Jaccard(G, Y2[0][0], Y2[0][1]))\n",
    "    degreeProd = float(predictor_DegreeProd(G, Y2[0][0], Y2[0][1]))\n",
    "    NewPredictor1 = 0\n",
    "    NewPredictor2 = 0\n",
    "    table[counter,:] = [Y2[0][0], Y2[0][1], tau, baseline, jaccard, degreeProd, NewPredictor1, NewPredictor2] # this is the initial table containing only the information related to the first missing link\n",
    "    counter += 1\n",
    "\n",
    "    for link in Y2[1:]: # we iterate through the missing links excluding the first link because we already computed it\n",
    "        if(link[0], link[1]) in Y:\n",
    "\n",
    "            tau = 1\n",
    "        else:\n",
    "            tau = 0\n",
    "        baseline = float(predictor_Baseline())\n",
    "        jaccard = float(predictor_Jaccard(G, link[0], link[1]))\n",
    "        degreeProd = float(predictor_DegreeProd(G, link[0], link[1]))\n",
    "        NewPredictor1 = 0\n",
    "        NewPredictor2 = 0\n",
    "        \n",
    "        table[counter,:] = [link[0], link[1], tau, baseline, jaccard, degreeProd, NewPredictor1, NewPredictor2]\n",
    "        counter += 1\n",
    "\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "c35c3953-b768-40bc-8481-a9efdf4b5c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6273\n"
     ]
    }
   ],
   "source": [
    "# Go      = nx.Graph([(1,2),(1,3),(3,4),(5,6),(4,6)]) # observed graph Go, from Lecture 4\n",
    "# missing = [(2,3),(4,5)]                             # list of edges missing from Go\n",
    "\n",
    "# nx.draw_networkx(Go,with_labels=True,node_size=600,width=2) # draw it pretty\n",
    "# limits=plt.axis('off')                                                             # turn off axes\n",
    "# plt.show() \n",
    "\n",
    "G = nx.read_edgelist(\"ChCh-Miner_durgbank-chem-chem.tsv\")\n",
    "\n",
    "def generateGo(G, alpha):\n",
    "    Go = G.copy()\n",
    "    mapping = {old_label:new_label for new_label, old_label in enumerate(Go.nodes())}\n",
    "    Go2 = nx.relabel_nodes(Go, mapping)\n",
    "    missingEdges = []\n",
    "    randomNum = 0\n",
    "    \n",
    "    for edge in Go2.edges():\n",
    "        randomNum = np.random.uniform(0, 1)\n",
    "        if randomNum > alpha:\n",
    "            Go2.remove_edge(edge[0], edge[1])\n",
    "            missingEdges.append(edge)\n",
    "    \n",
    "    return Go2, missingEdges\n",
    "\n",
    "Go, missing = generateGo(G, .87)\n",
    "\n",
    "table = apply_Predictors(Go, missing) # I had no idea how to calculate tau inside apply_predictor because I did not have access to the missing list\n",
    "table = table[np.argsort(table[:, 4])[::-1]] # modified from: https://stackoverflow.com/questions/2828059/sorting-arrays-in-numpy-by-column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "3dc7c573-44d6-4131-8a7c-e20fa72a2e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6274\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "efc59238-0b2c-4b52-84ee-31309132c350",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tabulate_TPR_FPR(S):\n",
    "    tkTrue = 0\n",
    "    tkFalse = 0\n",
    "    TPR = []\n",
    "    FPR = []\n",
    "    T = 0\n",
    "    F = 0\n",
    "    \n",
    "    for i in range(0, len(S)): # iterate once through S in order to determine the normalizing constants\n",
    "        if S[i][2] == 1:\n",
    "            T += 1\n",
    "        else:\n",
    "            F += 1\n",
    "            \n",
    "    for j in range(0, len(S)): # iterate again to calculate the TPR and FPR\n",
    "        if(S[j][2]) == 1:\n",
    "            tkTrue += 1\n",
    "        else:\n",
    "            tkFalse += 1\n",
    "        TPR.append(tkTrue / T)\n",
    "        FPR.append(tkFalse / F)\n",
    "        \n",
    "    columnOne = S[:, 0] # here I am getting the columns of the table in the desired return format\n",
    "    columnTwo = S[:, 1]\n",
    "    columnThree = S[:, 2]\n",
    "    columnFour = np.array(TPR)\n",
    "    columnFive = np.array(FPR)\n",
    "    columnSix = S[:, 3]\n",
    "\n",
    "    columnOne = columnOne.reshape(len(columnOne), 1) # reshaping columns, turning them into columns instead of horizontal lists\n",
    "    columnTwo = columnTwo.reshape(len(columnTwo), 1)\n",
    "    columnThree = columnThree.reshape(len(columnThree), 1)\n",
    "    columnFour = columnFour.reshape(len(columnFour), 1)\n",
    "    columnFive = columnFive.reshape(len(columnFive), 1)\n",
    "    columnSix = columnSix.reshape(len(columnSix), 1)\n",
    "\n",
    "    table = np.hstack((columnOne, columnTwo)) # here I am combining those columns into the table in the desired return format\n",
    "    table = np.hstack((table, columnThree))\n",
    "    table = np.hstack((table, columnFour))\n",
    "    table = np.hstack((table, columnFive))\n",
    "    table = np.hstack((table, columnSix))\n",
    "    return table    \n",
    "\n",
    "def calculate_AUC(TPR,FPR):\n",
    "    AUC = 0\n",
    "    TPR = np.insert(TPR, 0, 0) # prepend 0\n",
    "    FPR = np.insert(FPR, 0, 0)\n",
    "    for i in range(1, len(TPR)):\n",
    "        AUC += TPR[i] * (FPR[i] - FPR[i - 1]) # calculate AUC according to lecture notes 4\n",
    "    return AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "93d5a469-082c-4cdf-a0a5-5dcbc09dd13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "columnOne = table[:, 0] # here I am getting the columns of the table in the desired input format\n",
    "columnTwo = table[:, 1]\n",
    "columnThree = table[:, 2]\n",
    "columnFour = table[:, 3]\n",
    "\n",
    "columnOne = columnOne.reshape(len(columnOne), 1) # reshaping columns, turning them into columns instead of horizontal lists\n",
    "columnTwo = columnTwo.reshape(len(columnTwo), 1)\n",
    "columnThree = columnThree.reshape(len(columnThree), 1)\n",
    "columnFour = columnFour.reshape(len(columnFour), 1)\n",
    "\n",
    "baselineTable = np.hstack((columnOne, columnTwo)) # here I am combining the columns of the table in the desired return format\n",
    "baselineTable = np.hstack((baselineTable, columnThree))\n",
    "baselineTable = np.hstack((baselineTable, columnFour))\n",
    "baselineTable = baselineTable[np.argsort(baselineTable[:, 3])[::-1]] # here I am sorting the table by the score column in descending order\n",
    "\n",
    "columnOne = table[:, 0] # here I am repeating the process for the jaccard score\n",
    "columnTwo = table[:, 1]\n",
    "columnThree = table[:, 2]\n",
    "columnFour = table[:, 4]\n",
    "\n",
    "columnOne = columnOne.reshape(len(columnOne), 1) \n",
    "columnTwo = columnTwo.reshape(len(columnTwo), 1)\n",
    "columnThree = columnThree.reshape(len(columnThree), 1)\n",
    "columnFour = columnFour.reshape(len(columnFour), 1)\n",
    "\n",
    "jaccardTable = np.hstack((columnOne, columnTwo)) \n",
    "jaccardTable = np.hstack((jaccardTable, columnThree))\n",
    "jaccardTable = np.hstack((jaccardTable, columnFour))\n",
    "jaccardTable = jaccardTable[np.argsort(jaccardTable[:, 3])[::-1]]\n",
    "\n",
    "columnOne = table[:, 0] # here I am repeating the process for the degree product score\n",
    "columnTwo = table[:, 1]\n",
    "columnThree = table[:, 2]\n",
    "columnFour = table[:, 5]\n",
    "\n",
    "columnOne = columnOne.reshape(len(columnOne), 1) \n",
    "columnTwo = columnTwo.reshape(len(columnTwo), 1)\n",
    "columnThree = columnThree.reshape(len(columnThree), 1)\n",
    "columnFour = columnFour.reshape(len(columnFour), 1)\n",
    "\n",
    "degreeProductTable = np.hstack((columnOne, columnTwo)) \n",
    "degreeProductTable = np.hstack((degreeProductTable, columnThree))\n",
    "degreeProductTable = np.hstack((degreeProductTable, columnFour))\n",
    "degreeProductTable = degreeProductTable[np.argsort(degreeProductTable[:, 3])[::-1]]\n",
    "\n",
    "baselineTable = tabulate_TPR_FPR(baselineTable) # tabulate the tables\n",
    "jaccardTable = tabulate_TPR_FPR(jaccardTable)\n",
    "degreeProductTable = tabulate_TPR_FPR(degreeProductTable)\n",
    "baselineAUC = calculate_AUC(baselineTable[:, 3], baselineTable[:, 4]) # calculate the AUCs for each predictor\n",
    "jaccardAUC = calculate_AUC(jaccardTable[:, 3], jaccardTable[:, 4])\n",
    "degreeProductAUC = calculate_AUC(degreeProductTable[:, 3], degreeProductTable[:, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea508de-5b2f-49d5-9ef0-73124116e3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Degree Product AUC {:.5f} \\n\".format(degreeProductAUC))\n",
    "print(\"Jaccard AUC {:.5f} \\n\".format(jaccardAUC))\n",
    "print(\"Baseline AUC {:.5f} \\n\".format(baselineAUC))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
